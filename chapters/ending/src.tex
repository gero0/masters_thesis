\chapter{Podsumowanie}

W pracy wykonano badanie stabilności wartości miar dla problemu komiwojażera.
Wykonano implementację generatorów instancji testowych, algorytmów próbkowania przestrzeni rozwiązań,
oraz programu obliczającego wartości miar.
Zbadano 25 różnych miar dla 35 instancji problemu pochodzących z generatorów oraz ze zbioru tsplib.
Wykorzystano algorytm dwufazowy oraz \textit{snowball}.

Dla małych instancji o rozmiarze do 11 miast, wykonano przegląd zupełny i porównano wartości miar z estymacjami uzyskanymi
z próbkowania. Wykazano, że dla większości małych instancji możliwe jest uzyskanie dokładnych estymacji
większości miar w czasie znacznie krótszym od czasu potrzebnego na wykonanie algorytmu przeglądu zupełnego.
Wyniki sugerują również, że dla instancji tego rozmiaru bardziej efektywne obliczeniowo jest wykorzystanie
algorytmu \textit{snowball}.

Większe instancje poddano badaniu stabilności, polegającemu na okresowym zapisywaniu estymowanych wartości miar
podczas próbkowania. Uzyskano w ten sposób wartości szacowanych wielkości w odniesieniu do liczby optimów lokalnych w spróbkowanej przestrzeni.
Stwierdzono, że wartość większości miar jest niemożliwa do przewidzenia z dużą dokładnością.
Zauważono duży wpływ długości próbkowania oraz wybranego algorytmu na estymowane wartości miar przestrzeni rozwiązań.
Zidentyfikowano słabe punkty obu algorytmów próbkowania.
Algorytm dwufazowy nie radzi sobie z odnajdywaniem krawędzi w instancjach z dużą liczbą optimów lokalnych przy niedostatecznie długim próbkowaniu.
Algorytm \textit{snowball} może mieć trudności ze znalezieniem wszystkich optimów lokalnych w przestrzeni.

Zauważono różnice między różnymi typami instancji.
Instancje z miastami ułożonymi na siatce cechują się dużym stosunkiem liczby optimów lokalnych do liczby miast.
Instancje z miastami rozmieszczonymi w klikach mają zwykle mniej optimów lokalnych od podobnych rozmiarem instancji innego typu.

Przeprowadzenie badań wymagało wykonania ponad 20 miliardów wywołań procedury 2opt oraz funkcji obliczającej długość ścieżki.
Próbkowanie oraz obliczanie wartości miar wymagało kilkudniowych obliczeń
na wydajnej, 64-procesorowej maszynie. Obliczanie wartości miar dla największych sieci LON wymagało ponad 50GB pamięci RAM. \\
Z próbkowania uzyskano setki plików JSON reprezentujących otrzymane sieci LON, których przechowywanie wymagało wykorzystania ponad 300GB przestrzeni dyskowej.

Ze względu na ograniczony czas i moc obliczeniową, eksperymenty zostały przeprowadzone dla niewielkiej liczby instancji.
Rozwój badań w tym kierunku powinien obejmować przeprowadzenie analizy dla dużej liczby instancji tego samego typu i rozmiaru,
np. kilkanaście instancji o rozmiarze 100 i rozkładzie równomiernym.
Wtedy będzie można stwierdzić z większą pewnością, na które cechy przestrzeni wpływa dany sposób rozmieszczenia miast.
Należy również przeprowadzić dłuższe próbkowanie, szczególnie dla instancji z dużą ilością lokalnych optimów.

Aby dłuższe próbkowanie było możliwe, należy zadbać o wydajną implementację algorytmów.
Oprócz wymyślania nowych algorytmów, można również dokonywać prób zrównoleglenia istniejących.
Na potrzeby tej pracy zaimplementowano algorytm dwufazowy w sposób umożliwiający wykorzystanie wielu procesorów.
Kolejnym krokiem może być uruchomienie algorytmu w systemie rozproszonym i/lub na kartach GPU.