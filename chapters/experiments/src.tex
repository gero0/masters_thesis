\chapter{Badania eksperymentalne}

\section{Zaimplementowane algorytmy}
\subsection{Próbkowanie dwufazowe} \label{section:tp}
Próbkowanie dwufazowe swoją nazwę zawdzięcza procesowi próbkowania składającemu się z dwóch oddzielnych faz
- próbkowania wierzchołków oraz próbkowania krawędzi - wykonywanych jedna po drugiej.
Istotną zaletą tego podejścia jest jego stosunkowo prosta implementacja.

Zaimplementowany algorytm pochodzi z pracy\cite{DBLP:conf/depcos/BozejkoGNAB18}.
Został on przygotowany specjalnie do próbkowania przestrzeni rozwiązań problemu komiwojażera.
Próbkowanie wierzchołków odbywa się poprzez generowanie losowych rozwiązań, a następnie ich optymalizacji algorytmem 2-opt.
Próbkowanie krawędzi polega na wielokrotnym poddaniu każdego ze znalezionych wcześniej lokalnych optimów $n_i$ operacji perturbacji typu 2-exchange,
a następnie poddaniu powstałego rozwiązania optymalizacji algorytmem 2-opt typu \textit{first-improvement} uzyskując w ten sposób lokalne optimum $n_j$.
Następnie dodawana jest krawędź między $n_i$ a $n_j$, lub - jeśli już taka istnieje - jej waga jest zwiększana o 1.

Algorytm przyjmuje trzy parametry: pożądaną liczbę wierzchołków do wygenerowania ($n_{max}$), maksymalną liczbę prób generowania wierzchołka ($n_{att}$)
oraz maksymalną liczbę prób generowania krawędzi($e_{att}$).
Implementacja zastosowana w tej pracy dodatkowo powtarza cały proces kilkukrotnie, za każdym razem zapisując zebrane próbki do pliku.

Algorytm w postaci pseudokodu został przedstawiony na listingu \ref{alg:tp}.

\subsection{Snowball} \label{section:snowball}
Próbkowanie typu Snowball wywodzi się z techniki używanej w badaniach z dziedziny socjologii, w której ludzie należący do próby z populacji
rekrutują kolejnych uczestników badania spośród swoich znajomych.
W kontekście badania przestrzeni rozwiązań technika ta została zaprezentowana w pracy\cite{DBLP:conf/ppsn/VerelDOT18}, gdzie została wykorzystana
do próbkowanie przestrzeni problemu kwadratowego przypisania (QAP).

Próbkowanie składa się z etapów procedury \textit{snowball} próbkującej "wgłąb" i losowego spaceru(ang. \textit{random walk}).
Próbkowanie \textit{snowball} polega na wybraniu rozwiązania startowego i przeszukaniu jego najbliższego sąsiedztwa.
Następnie operacja ta jest powtarzana dla każdego rozwiązania w tym sąsiedztwie. Proces powtarza się aż do osiągnięcia z góry ustalonej głębokości
przeszukiwania. Następnie rozpoczyna się procedura losowego spaceru - wybierane jest kolejne rozwiązanie startowe
ze zbioru sąsiadów poprzedniego rozwiązywania startowego (lub rozwiązanie losowe, jeśli to sąsiedztwo jest puste) i proces \textit{snowball}
rozpoczyna się od nowa. Procedura jest powtarzana aż osiągnięty zostanie z góry ustalony limit długości spaceru.

Zaimplementowany algorytm jest próbą adaptacji tej techniki do zadania przeszukiwania przestrzeni
problemu komiwojażera. Do najważniejszych modyfikacji należy zastąpienie funkcji optymalizacji lokalnej typu \textit{hillclimb}
optymalizacją 2opt, implementacja odpowiedniej funkcji celu oraz operacji mutacji typu 2-exchange.

Algorytm w postaci pseudokodu został przedstawiony na listingu \ref{alg:snowball}.

\vspace{1em}

\begin{algorithm}[H]
    \caption{Próbkowanie dwufazowe - pseudokod}\label{alg:tp}

    \KwData{\\
        \Indp \Indp
        $n_{max}$ - żądana liczba wierzchołków\\
        $n_{att}$ - liczba prób generowania wierzchołków\\
        $e_{att}$ - liczba prób generowania krawędzi\\
        $n_{runs}$ - liczba powtórzeń\\
        $D$ - stała D krawędzi
    }

    \vspace{1em}

    $N \gets \{\}$\;
    $E \gets \{\}$\;
    \For{$i\gets1$ \KwTo $n_{runs}$}{
        $probkujWierzcholki(N, n_{max}, n_{att})$\;
        $probkujKrawedzie(N, E, e_{att})$\;
        $zapiszDoPliku(N, E)$\;
    }
    \vspace{1em}

    \SetKwFunction{FV}{probkujWierzcholki}
    \SetKwProg{Fn}{function}{:}{}

    \Fn{\FV{$N, n_{max}, n_{att}$}}{
        \For{$i\gets1$ \KwTo $n_{max}$}{
            \For{$i\gets1$ \KwTo $n_{att}$}{
                $s \gets losoweRozwiazanie()$\;
                $s \gets 2opt(s)$\;
                $N \gets N \cup \{s\}$\;
            }
        }
    }
    \textbf{end}

    \vspace{1em}

    \SetKwFunction{FE}{probkujKrawedzie}

    \Fn{\FE{$N, E, e_{att}$}}{
        \ForEach{$n \in{N}$}{
            \For{$i\gets1$ \KwTo $e_{att}$}{
                $s \gets 2exchangeMutacja(n, D)$\;
                $s \gets 2optFirstImprovement(s)$\;
                \If{$s \in{N}$}{
                    $E \gets E \cup \{(n, s)\}$\;
                    $w_{ns} \gets w_{ns} + 1$\;
                }
            }
        }
    }
    \textbf{end}

    \vspace{1em}

\end{algorithm}

\begin{algorithm}[p]
    \caption{Próbkowanie snowball - pseudokod}\label{alg:snowball}

    \KwData{\\
        \Indp \Indp
        $w_{len}$ - długość losowego spaceru\\
        $m$ - liczba prób przeszukania sąsiedztwa\\
        $depth$ - głębokość przeszukiwania\\
        $D$ - stała D krawędzi\\
        $s_{tresh}$ - interwał zapisu
    }

    \vspace{1em}
    $s_1 \gets losoweRozwiazanie()$\;
    $n_1 \gets 2opt(s_1)$\;

    $N \gets \{ n_1 \}$\;
    $E \gets \{\}$\;
    \For{$j\gets1$ \KwTo $n_{runs}$}{
        \For{$i\gets1$ \KwTo $w_{len}$}{
            $snowball(n_i, m, depth)$\;
            $n_{i+1} \gets losowySpacer(n_i)$\;
        }
    }
    $zapiszDoPliku(N, E)$\;
    \vspace{1em}

    \SetKwFunction{FS}{snowball}
    \SetKwProg{Fn}{function}{:}{}

    \Fn{\FS{$n, m, depth$}}{
        \If{$d > 0$}{
            \For{$i\gets1$ \KwTo $m$}{
                $s \gets 2opt(2exchangeMutacja(n, D))$\;
                $N \gets N \cup \{ s \}$\;
                \If{$|N| \hspace{0.5em} mod \hspace{0.5em} s_{tresh} = 0$}{
                    $zapiszDoPliku(N, E)$\;
                }
                \uIf{$(n, s) \in{E}$}{
                    $w_{ns} \gets w_{ns} + 1$\;
                }
                \Else{
                    $E \gets E \cup \{ (n, s) \}$\;
                    $w_{ns} \gets 1$\;
                    $snowball(s, m, d-1)$\;
                }
            }
        }
    }
    \textbf{end}

    \vspace{1em}

    \SetKwFunction{FW}{losowySpacer}

    \Fn{\FW{$n_i$}}{
        $neighbours \gets \{ s: (n_i, s) \in E \land s \notin \{ n_0...n_i \} \}$\;
        \uIf{$neighbours \neq \emptyset $}{
            $n_{i+1} \gets losowyElementZeZbioru(neighbours)$\;
        }
        \Else{
            $s \gets losoweRozwiazanie()$\;
            $n_{i+1} \gets 2opt(s)$\;
            $N \gets N \cup \{ n_{i+1} \}$\;
            \If{$|N| \hspace{0.5em} mod \hspace{0.5em} s_{tresh} = 0$}{
                $zapiszDoPliku(N, E)$\;
            }
        }
        \Return $n_{i+1}$
    }
    \textbf{end}

    \vspace{1em}

\end{algorithm}

\newpage

\subsection{Przegląd zupełny}
Ze względu na złożoność problemu komiwojażera przegląd zupełny można zastosować tylko do bardzo małych instancji problemu.
Przegląd polega na wygenerowaniu wszystkich możliwych rozwiązań danej instancji, wykonaniu na nich optymalizacji 2-opt w celu znalezienia
optimów lokalnych a następnie znalezieniu krawędzi oraz obliczeniu ich wag. Dla każdego z rozwiązań generowane są wszystkie
permutacje, które mogą powstać poprzez D-krotne wykonanie na rozwiązaniu operacji 2-exchange. Jeśli wśród tych permutacji znajduje się jedno ze znalezionych wcześniej
lokalnych optimów, oznacza to, że spełniony jest warunek \ref{eq:escape_edge_cond} i dodawana jest nowa krawędź lub zwiększona zostaje waga istniejącej.

\begin{algorithm}[]
    \caption{Przegląd zupełny}\label{alg:exhaustive}
    $S \gets \{\}$\;
    $P \gets wygenerujWszystkiePermutacje()$\;
    \ForEach{$p \in P$}{
        $lo \gets 2opt(p)$\;
        $S \gets S \cup \{(p, lo)\}$\;
    }

    \SetKwProg{Fn}{function}{:}{}

    \ForEach{$(p, lo) \in S$}{
        \ForEach{$n \in N$}{
            \If{$wZasiegu2Exchange(p, n, D)$}{
                \uIf{$(n, lo) \in E$}{
                    $w_{n, lo} \gets w_{n, lo} + 1$\;
                }\Else{
                    $E \gets E \cup \{(n, lo)\}$\;
                    $w_{n, lo} = 1$\;
                }
            }
        }
    }

    \SetKwFunction{FI}{wZasiegu2Exchange}

    \vspace{1em}

    \Fn{\FI{$p, n, D$}}{
        $permutacje \gets \{p\}$\;
        \For{$i \in 1..D$}{
            $nowe\_perm \gets \{\}$\;
            \ForEach{$perm \in permutacje$}{
                $pochodne\_perm \gets 2exchangeWszystkiePermutacje(permutacje)$\;
                \ForEach{$poch\in pochodne\_perm$}{
                    \If{poch = n}{
                        \Return{true}\;
                    }
                    $nowe\_perm \gets nowe\_perm \cup \{poch\}$\;
                }
            }
            $permutacje \gets nowe\_perm$\;
        }
        \Return{false}\;
    }
    \textbf{end}

\end{algorithm}

\section{Instancje testowe}
Do badań wykorzystano instancje testowe wygenerowane losowo oraz wybrane instancje ze zbioru TSPLIB.
Zaimplementowano trzy generatory tworzące różne typy instancji testowych: z miastami rozłożonymi równomiernie,
z miastami rozłożonymi w klastrach oraz z miastami ułożonymi na siatce.
Wygenerowano instancje testowe każdego z trzech typów instancji losowych o rozmiarach 7, 8, 9, 10, 11 oraz 20, 50, 80 i 100.
Uzyskano w ten sposób 27 instancji problemu.
Ze zbioru TSPLIB wybrano instancje o podobnych rozmiarach: \textbf{burma14}, \textbf{ulysses22}, \textbf{att48}, \textbf{berlin52}, \textbf{pr76}, \textbf{eil76}, \textbf{rat99},
\textbf{bier127}.
W sumie badanie przeprowadzono na 35 instancjach problemu.

\subsection*{Miasta rozmieszczone równomiernie}
Generator losowo rozmieszcza miasta na wirtualnej planszy o ustalonym rozmiarze.\\
Współrzędne miast generowane są losowo z rozkładu równomiernego.
W dalszej części dokumentu instancje wygenerowane tym generatorem będą nazywane \textbf{uniform\_<liczba miast>}.

Przykład wygenerowanej instancji został przedstawiony na rysunku \ref{fig:uniform_example}.

\subsection*{Miasta rozmieszczone w klastrach}
Miasta umieszczane są blisko siebie w kilku grupach oddzielonych większymi odległościami.
W dalszej części dokumentu instancje wygenerowane tym generatorem będą nazywane \textbf{cliques\_<liczba miast>}.
Przykład wygenerowanej instancji został przedstawiony na rysunku \ref{fig:clique_example}.


\subsection*{Miasta rozmieszczone na siatce}
Miasta umieszczane są na siatce, w stałej odległości od swoich sąsiadów.
W dalszej części dokumentu instancje wygenerowane tym generatorem będą nazywane \textbf{grid\_<liczba miast>}.
Przykład wygenerowanej instancji został przedstawiony na rysunku \ref{fig:grid_example}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.46\textwidth]{chapters/experiments/img/uniform_example.png}
    \caption{Wizualizacja przykładowej wygenerowanej instancji z miastami rozmieszczonymi równomiernie dla 100 miast}
    \label{fig:uniform_example}
\end{figure}

\newpage

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.60\textwidth]{chapters/experiments/img/clique_example.png}
    \caption{Wizualizacja przykładowej wygenerowanej instancji z miastami rozmieszczonymi w klastrach dla 100 miast}
    \label{fig:clique_example}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.60\textwidth]{chapters/experiments/img/grid_example.png}
    \caption{Wizualizacja przykładowej wygenerowanej instancji z miastami rozmieszczonymi na siatce dla 100 miast}
    \label{fig:grid_example}
\end{figure}

\section{Opis badań}

Badania podzielono na trzy etapy: Porównanie wartości metryk z przeglądem zupełnym dla małych instancji,
badanie stabilności średnich instancji, oraz badanie stabilności dużych instancji.

W tym rozdziale przedstawione zostaną tabele i wykresy wygenerowane z wyników próbkowania.
Nazwy metryk są identyczne z nazwami objaśnionymi w rozdziale \ref{sec:metrics}.
Ponadto występują pojęcia:

\begin{itemize}
    \item node\_count - liczba wierzchołków,
    \item edge\_count - liczba krawędzi,
    \item opt\_count - liczba wywołań funkcji 2opt,
    \item oracle\_count - liczba wykonanych obliczeń długości ścieżki (metodą obliczenia przyrostu długości stosowanej w 2opt).
    \item twophase - algorytm dwufazowy
\end{itemize}

Wszystkie badania wykonano wykorzystując model krawędzi typu \textit{Escape Edges} z parametrem $D$ o wartości 2.

\subsection{Porównanie wartości metryk dla małych instancji}
Dla małych instancji wygenerowanych losowo (uniform, grid, cliques) o rozmiarach 7 do 11
możliwe jest wykonanie przeglądu zupełnego.
Na tych instancjach wykonano próbkowanie algorytmami dwufazowym oraz \textit{snowball}, z różnym zestawem parametrów.

Dla algorytmu dwufazowego wykonano próbkowanie dla różnych wartości parametru $n_{max}$ (liczby żądanych wierzchołków): 10, 40, 100 oraz 1000.
Parametry $n_{att}$, $e_{att}$ ustawiono na równe $n_{max}$, a parametr $n_{runs}$ na 1.

Dla algorytmu \textit{snowball} wykonano próbkowanie dla różnych wartości parametru $w_{len}$ (długości losowego spaceru): 1, 10, 100 oraz 1000.
Pozostałe parametry ustawiono następująco: $m$ = 100, $depth$ = 3.

Uzyskane wartości porównano z wartościami uzyskanymi z przeglądu zupełnego.
Wyniki przedstawiono w tabelach od \ref{tab:comp_uniform_7_snowball} do \ref{tab:comp_grid_11_twophase}.
W tabeli przedstawiono wartości metryk uzyskane w przeglądzie zupełnym oraz wartości uzyskane z próbkowania.
Dodatkowo w nawiasie podana została wartość błędu obliczona z wzoru \ref{eq:relError}.
\begin{equation}
    \label{eq:relError}
    E = \frac{|R - S|}{R} \cdot 100\%
\end{equation}
Gdzie:
\begin{itemize}
    \item E - wartość błędu
    \item R - wartość rzeczywista (z przegl. zupełnego)
    \item S - wartość otrzymana z próbkowania.
\end{itemize}

Wartości, dla których błąd nie wyniósł 0 zostały dodatkowo oznaczone w tabeli grubą czcionką.
Przebadano wszystkie miary opisane w sekcji \ref{sec:metrics} za wyjątkiem assortativity\_deg - wartość ta dla małych instancji zwykle przyjmowała
nieprawidłową wartość (NaN), więc zdecydowano o jej wykluczeniu.

\subsubsection{Wyniki}

\include{tables.tex}

Najbardziej rzucającymi się w oczy metrykami są avg\_loop\_weight i distLO.
We wszystkich przypadkach są one znacznie większe od wartości uzyskanych z przeglądu zupełnego.
Nie jest to zaskakujące. Algorytm przeglądu zupełnego jednokrotnie sprawdza każde rozwiązanie w przestrzeni przeszukiwania pod kątem
możliwości utworzenia krawędzi między optimami lokalnymi, lub zwiększenia wagi istniejącej.
Po sprawdzeniu wszystkich rozwiązań algorytm kończy pracę.
Algorytmy próbkowania nie kończą pracy aż do momentu osiągnięcia warunku zatrzymania.
Ze względu na swój losowy charakter, po operacji perturbacji często trafiają na te same rozwiązania
(szczególnie w przypadku małych instancji) i powodują zwiększanie wagi krawędzi, w tym pętli, do wartości znacznie większych od rzeczywistych.
Dlatego metryki, których wartość zależy od bezwzględnych wartości wag, a nie od stosunku wag różnych krawędzi nie dają użytecznej informacji na temat małych instancji.
Z tego też powodu ich wartość nie będzie brana pod uwagę w ocenie działania algorytmu.

W przypadku najmniejszych instancji o rozmiarze 7, błąd uzyskany po porównaniu wartości metryk
wynosił 0 lub był bliski 0 dla wszystkich metryk oprócz avg\_loop\_weight i distLO.
Wyjątkiem była instancja uniform\_7, gdzie wartości błędów były wyższe dla obu algorytmów.
W tej instancji algorytm snowball poradził sobie znacznie lepiej - brak błędu dla większości
metryk wystąpił już dla parametru $w_{len}$ równego 10, natomiast algorytm dwufazowy
podobny wynik uzyskał dopiero dla parametru $n_{max}$ równego 1000 - wymagało to ponad 600 razy więcej wywołań funkcji optymalizującej.
Dla instancji tej wielkości przegląd zupełny jest szybki, dlatego nie ma sensu stosować dla nich próbkowania.

Obu algorytmom udało się dobrze odwzorować cechy przestrzeni rozwiązań instancji uniform\_8 i grid\_8 (z wyjątkiem distLO i avg\_loop\_weight),
w czasie próbkowania kilkukrotnie krótszym od czasu trwania przeglądu zupełnego. Wyjątkiem okazała się instancja cliques\_8, której dokładne spróbkowanie
udało się dopiero dla $n_{max}$ równego 100 - próbkowanie trwało prawie dwa razy tyle czasu, co przegląd zupełny.
Algorytm snowball poradził sobie znakomicie już dla wartości $w_{len}$ równej 10 - próbkowanie było ponad dwukrotnie krótsze od przeglądu zupełnego.

Dla instancji uniform\_9 i cliques\_9 oba algorytmy dobrze odwzorowały przestrzeń w czasie znacznie krótszym od czasu przeglądu zupełnego.
Jednak w przypadku instancji grid\_9 nawet najdłuższe przebiegi testowanych algorytmów nie pozwoliły na uzyskanie zerowego błędu dla wszystkich
miar z wyłączeniem distLO i avg\_loop\_weight.
Algorytm snowball ujawnia tu swoją wadę - mimo znalezienia wszystkich krawędzi i wierzchołków wartości miar largest\_clique\_size i reciprocity
nie zą zgodne z wartościami uzyskanymi z przeglądu zupełnego. Jest to spowodowane tym, że zarówno przegląd zupełny jak i algorytm dwufazowy używają
algorytmu 2opt typu fist-improvement w procedurze perturbacji. Algorytm snowball używa zaś optymalizacji typu best-improvement, co powoduje nieznaczne,
ale widoczne różnice topologii zbudowanej sieci LON.
Pomimo korzystania z 2opt typu fist-improvement, algorytm dwufazowy nie poradził sobie z dokładnym odwzorowaniem przestrzeni instancji grid\_9 i ostatecznie
lepszy w tym przypadku okazał się algorytm snowball.

W przypadku instancji o rozmiarze 10 coraz bardziej widoczna staje się różnica między poszczególnymi typami instancji - instancje z miastami
ułożonymi w klastrach nie sprawiają problemów - oba algorytmy dla większości miar otrzymują wartość prawdziwą w czasie krótszym od przeglądu zupełnego.
Instancja uniform\_10 nie jest już idealnie odwzorowywana - algorytmy nie docierają do niektórych krawędzi i pojawiają się niewielkie błędy.
Instancja grid\_10 sprawia problemy obu algorytmom. Warto jednak zauważyć, że wartości błędów dla przebiegu snowball\_1000 są mniejsze od błędów
z przebiegu dwufazowy\_1000 pomimo tego, że ten drugi trwa 10 razy dłużej.

Instancja uniform\_11 okazała się rzadkim przypadkiem, w którym algorytm dwufazowy poradził sobie lepiej od algorytmu snowball w podobnym czasie.
Snowball okazuje się lepszy dla instancji cliques\_11 - oba algorytmy w najdłuższym przebiegu znajdują prawdziwą wartość większości miar, ale snowball robi to szybciej.
Instancja grid\_11 zawiera dużą ilość wierzchołków i krawędzi - nawet najdłuższe przebiegi obu algorytmów nie były w stanie znaleźć wszystkich,
co poskutkowało znacznymi błędami.

\subsection{Badanie stabilności dla średnich instancji}
Instancje \textbf{burma14}, \textbf{ulysses22} ze zbioru tsplib oraz wygenerowane instancje
\textbf{cliques\_20}, \textbf{uniform\_20} oraz \textbf{grid\_20} są zbyt duże, by wykonać dla nich przegląd zupełny,
ale zbyt małe, żeby próbkować je z takimi samymi parametrami, jak większe instancje.
Z tego powodu badania przeprowadzone dla tych instancji umieszczono w osobnej sekcji.
Dla instancji tego typu wykonano bardziej szczegółowe próbkowanie z mniejszymi interwałami zapisu.

Próbkowanie algorytmem snowball wykonano z następującymi parametrami:
\begin{itemize}
    \item $w_{len}$ - długość losowego spaceru - 10000
    \item $m$ - liczba prób przeszukania sąsiedztwa - 100
    \item $depth$ - głębokość przeszukiwania - 3
\end{itemize}
Zapis wyników wykonywano przy każdym znalezionym wierzchołku.
Wyjątkiem była instancja grid\_20 - tu zapis wykonywano co 100 wierzchołków z powodu dużej ilości optimów lokalnych.

Próbkowanie algorytmem dwufazowym przeprowadzono z następującymi parametrami:
\begin{itemize}
    \item $n_{max}$ - żądana liczba wierzchołków - 1
    \item $n_{att}$ - liczba prób generowania wierzchołków - 1000
    \item $e_{att}$ - liczba prób generowania krawędzi - 10
    \item $n_{runs}$ - liczba powtórzeń - 1000
\end{itemize}
Zapis wyników wykonywano po zakończeniu każdego powtórzenia.

Utworzono wykresy przedstawiające zależność wartości miar od liczby spróbkowanych wierzchołków.
Przedstawiono je na rysunkach od \ref{fig:small_edge_count} do \ref{fig:small_missed}.

\subsubsection{Wyniki}

\def\metricsSmall{
    {edge_count/Liczba krawędzi},
    {edge_to_node/Stosunek liczby krawędzi do liczby wierzchołków},
    {assortativity_deg/Współczynnik różnorodności grafu},
    {avg_fitness/Średnia wartość funkcji celu w znalezionych optimach lokalnych},
    {conrel/Współczynnik conrel},
    {density/Gęstość grafu},
    {distLO/Współczynnik distLO},
    {reciprocity/Współczynnik wzajemności grafu},
    {largest_clique_size/Rozmiar największej kliki w grafie},
    {num_sources/Liczba źródeł w grafie},
    {num_sinks/Liczba ścieków w grafie},
    {num_subsinks/Liczba subsinks w grafie},
    {avg_in_degree/Średni stopień wchodzący wierzchołków w grafie},
    {max_in_degree/Maksymalny stopień wchodzący wśród wierzchołków w grafie},
    {max_out_degree/Średni stopień wychodzący wierzchołków w grafie},
    {avg_out_degree/Maksymalny stopień wychodzący wśród wierzchołków w grafie},
    {avg_loop_weight/Średnia waga pętli w grafie},
    {avg_path_len/Średnia waga pętli w grafie},
    {avg_go_path_len/Średnia długość istniejących ścieżek do globalnego optimum},
    {max_go_path_len/Długość najdłuższej istniejącej ścieżki do globalnego optimum},
    {go_path_ratio/Stosunek liczby wierzchołków, z których istnieje ścieżka do globalnego optimum do liczby wszystkich wierzchołków},
    {funnel_num/Liczba lejów w przestrzeni},
    {max_funnel_size/Rozmiar największego leja w przestrzeni},
    {mean_funnel_size/Średni rozmiar lejów w przestrzeni},
    {num_cc/Liczba spójnych podgrafów},
    {largest_cc/Rozmiar największego spójnego podgrafu},
    {largest_cc_radius/Promień największego spójnego podgrafu}}


\foreach \metric/\cap in \metricsSmall{
    \begin{figure}[p]
        \centering
        \includegraphics[width=\textwidth]{chapters/experiments/img/merged_plots/per1_all/\metric.png}
        \caption{\cap \space w zależności od liczby wierzchołków}
        \label{fig:small_\metric}
    \end{figure}
}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{chapters/experiments/img/merged_plots/per1_all/missed.png}
    \caption{Liczba nieudanych prób tworzenia krawędzi w zależności od liczby wierzchołków - próbkowanie dwufazowe}
    \label{fig:small_missed}
\end{figure}

Zależność liczby krawędzi od liczby wierzchołków jest nieliniowa dla wszystkich zbadanych instancji i obu algorytmów.
Dla instancji typu grid oraz ulysses22 wykres tej zależności ma postać ''gładkiej'' krzywej.
W pozostałych przypadkach wzrost jest znacznie mniej stabilny - pojawiają się ''schodki'', miejsca w których wzrost
spowalnia i gwałtownie rośnie.
Sugeruje to, że przewidzenie wartości stosunku krawędzi do wierzchołków może być możliwy w przypadku
instancji z miastami ułożonymi na siatce.

W przypadku metryki assortativity\_deg można zaobserwować pewną właściwość.
Na początku próbkowania wartość metryki zmienia się gwałtownie, zwiększając i zmniejszając się naprzemiennie.
Po pewnym czasie jednak się stabilizuje, widoczne jest to zwłaszcza dla instancji z większą ilością optimów lokalnych.
Nadal obecne są wahania wartości, ale są one znacznie mniejsze.
Wyjątkiem jest instancja grid\_20 próbkowana algorytmem snowball.
W tym przypadku wartość zmienia się znacznie przez cały okres próbkowania.
W wielu przypadkach ostatnia uzyskana wartość różni znacznie pomiędzy algorytmami.

W większości przypadków średnia wartość funkcji celu wierzchołków przestrzeni zwiększa się wraz z ilością wierzchołków.
W niektórych przypadkach występuje początkowo duża wartość i gwałtowny spadek, zwykle w przypadku próbkowania dwufazowego.
W innych przypadkach wartość wzrasta przez cały czas.
Wykresy wartości uzyskane z obu algorytmów różnią się, ale wartości uzyskane na końcu próbkowania są do siebie podobne.
Niska wartość funkcji celu na początku i powolny wzrost oznacza, że w badanych instancjach szybko znajdowane były
najlepsze rozwiązania w przestrzeni.

Wartość współczynnika conrel jest nieprzewidywalna.
Dla niektórych instancji utrzymuje się na podobnym poziomie przez większość czasu,
ale gwałtownie zwiększa się pod koniec próbkowania.
W innych wartość miary znacznie zmienia się w trakcie procesu, formując ostre piki.

Gęstość grafu w każdym przypadku osiągała wysoką wartość, by następnie gwałtownie spaść i ustabilizować się w pewnym zakresie.
W kilku przypadkach występował wzrost gęstości grafu pod koniec próbkowania.
Miara jest najbardziej stabilna dla instancji z miastami rozłożonymi równomiernie.

Miara distLO jest niestabilna, występują częste nagłe wzrosty i spadki jej wartości.
W kilku przypadkach wystąpił duży spadek pod koniec próbkowania, w innych - gwałtowny wzrost.

Współczynnik wzajemności (reciprocity) również jest niestabilny.
W niektórych przypadkach występuje gwałtowny wzrost i spadek wartości na początku próbkowania.
Ciekawa jest instancja grid\_20 - po spróbkowaniu odpowiednio dużej liczby wierzchołków
wartość wzrost tej miary jest zbliżony do wzrostu liniowego.

Rozmiar największej kliki zmienia się ''schodkowo'' w momencie, w którym albo ze spróbkowanych wierzchołków
powstanie większa klika lub nowy wierzchołek zostanie odnaleziony w już istniejącej.
Wyniki sugerują że możliwe jest oszacowanie wielkości największej kliki przestrzeni na podstawie wartości
z krótszego próbkowania, zwłaszcza na podstawie danych z próbkowania dwufazowego, gdzie
wartość zmienia się mniej gwałtownie. Ze względu na stopniowy i nieliniowy charakter wzrostu zmiennej,
dokładność takiego szacowania nie będzie duża.

Liczba źródeł, ścieków i tzw. subsinks w grafie w wielu przypadkach początkowo rośnie, by nagle zmaleć na końcu próbkowania.
W przypadkach ze zbioru TSPLIB po pewnym czasie liczba ścieków i subsinks przestała się zmieniać.
Wszystkie trzy miary są niestabilne, mają charakter nieprzewidywalny.

Charakterystyka wzrostu wartości średniego stopnia wchodzącego wierzchołka jest bardziej zbliżona do liniowej
w przypadku próbkowania dwufazowego. W instancjach cliques\_20, uniform\_20 i burma14 występuje
wzrost przyspieszenie wzrostu pod koniec próbkowania.
W tych przypadkach z dużym prawdopodobieństwem algorytmy znalazły wszystkie optima lokalne.
Może być to powodem tego zjawiska.
W przypadku instancji grid\_20 o liczbie optimów lokalnych znacznie wyższej od pozostałych instancji tego rozmiaru,
wynik z próbkowania snowball ma charakter eksponencjalny.
Podobnie wyglądają miary największego stopnia wchodzącego, średniego stopnia wychodzącego i maksymalnego stopnia wychodzącego.

Średnia waga pętli w grafie jest niestabilna, w niektórych przypadkach wzrost jest bliski liniowego, w innych
eksponencjalnego, a w pozostałych jest chaotyczny.

Średnia długość ścieżki w grafie zwiększa się gwałtownie na początku, po czym stabilizuje.
Pojawiają się przypadki odstające (w grid\_20 przy próbkowaniu snowball wartość dość szybko maleje),
ale dla większości przypadków wahania wartości po ustabilizowaniu są niewielkie.
Podobnie jest w przypadku średniej długości ścieżek do globalnego optimum.

Długość najdłuższej ścieżki do globalnego optimum zmniejsza i zwiększa się gwałtownie.
Jest nieprzewidywalna.

Współczynnik go\_path\_ratio zmienia się zupełnie inaczej w zależności od algorytmu próbkowania.
Próbkowanie dwufazowe rośnie gwałtownie i bardzo wcześnie się stabilizuje.
Próbkowanie snowball prowadzi natomiast do powolnego wzrostu z okazjonalnymi spadkami wartości.
Oba algorytmy osiągają podobną końcową wartość miary, ale próbkowanie dwufazowe osiąga ją przy mniejszej
liczbie spróbkowanych wierzchołków.

Liczba lejów w przestrzeni jest miarą niestabilną, wartość miary zmienia się w zupełnie inny sposób
dla różnych instancji.

Rozmiar największego leja w przestrzeni rośnie liniowo dla danych uzyskanych z próbkowania
dwufazowego. Wartość uzyskana z próbkowania snowball nie jest tak stabilna.

Wzrost średniego rozmiaru lejów dla próbkowania dwufazowego również jest bliski liniowego,
widać jednak na nim pewne odchylenia. W ramach wzrostu ilości optimów lokalnych w przestrzeni,
wykres uzyskany ze snowball coraz bardziej zbliża się do wzrostu eksponencjalnego.

Liczba spójnych podgrafów szybko stabilizuje się na stałej wartości dla większości przypadków.

Rozmiar największego spójnego podgrafu rośnie liniowo dla wszystkich instancji i algorytmów.

Promień największego spójnego podgrafu zmienia się wielokrotnie o wartość 1 dla większości przypadków

Im więcej wierzchołków znajduje się w zbiorze, tym więcej prób tworzenia krawędzi w algorytmie dwufazowym
się powiedzie. Dlatego można zaobserwować delikatne wypłaszczenie krzywej na wykresie liczby nieudanych prób.
Wyjątkiem jest tu instancja grid\_20  - jest to spowodowane tym że algorytm nie znalazł wszystkich optimów
lokalnych przed końcem próbkowania.

\subsection{Badanie stabilności dla dużych instancji}
W tej sekcji opisano badania przeprowadzone dla instancji o rozmiarze 48 i większym.
Próbkowanie przeprowadzono przez ustaloną z góry liczbę powtórzeń, zapisując stan przestrzeni po zakończeniu każdego powtórzenia.

Próbkowanie algorytmem snowball wykonano z następującymi parametrami:
\begin{itemize}
    \item $w_{len}$ - długość losowego spaceru - 10000
    \item $m$ - liczba prób przeszukania sąsiedztwa - 100
    \item $depth$ - głębokość przeszukiwania - 3
\end{itemize}

Próbkowanie algorytmem \textit{snowball} prowadzono do zakończenia losowego spaceru lub osiągnięcia liczby 100000 wierzchołków.
Dla instancji \textbf{cliques\_50} z powodu małej liczby optimów lokalnych zapis wykonywano co 100 znalezionych wierzchołków.
Dla pozostałych instancji stan próbkowania zapisywany był co 1000 znalezionych wierzchołków.

Próbkowanie algorytmem dwufazowym przeprowadzono z następującymi parametrami:
\begin{itemize}
    \item $n_{max}$ - żądana liczba wierzchołków - 1000
    \item $n_{att}$ - liczba prób generowania wierzchołków - 1000
    \item $e_{att}$ - liczba prób generowania krawędzi - 1000
    \item $n_{runs}$ - liczba powtórzeń - 100
\end{itemize}

Po zakończeniu próbkowania dla każdego zapisanego stanu przestrzeni obliczono wartości badanych miar. W ten sposób uzyskano
wartości miar dla różnych etapów próbkowania przestrzeni.

Utworzono wykresy przedstawiające zależność wartości miar od liczby spróbkowanych wierzchołków.
Przedstawiono je na rysunkach od \ref{fig:main_snowball_edge_count} do \ref{fig:main_twophase_missed}.

\def\metrics{
    {edge_count/Liczba krawędzi},
    {edge_to_node/Stosunek liczby krawędzi do liczby wierzchołków},
    {assortativity_deg/Współczynnik różnorodności grafu},
    {avg_fitness/Średnia wartość funkcji celu w znalezionych optimach lokalnych},
    {conrel/Współczynnik conrel},
    {density/Gęstość grafu},
    {distLO/Współczynnik distLO},
    {reciprocity/Współczynnik wzajemności grafu},
    {largest_clique_size/Rozmiar największej kliki w grafie},
    {num_sources/Liczba źródeł w grafie},
    {num_sinks/Liczba ścieków w grafie},
    {num_subsinks/Liczba subsinks w grafie},
    {avg_in_degree/Średni stopień wchodzący wierzchołków w grafie},
    {max_in_degree/Maksymalny stopień wchodzący wśród wierzchołków w grafie},
    {max_out_degree/Średni stopień wychodzący wierzchołków w grafie},
    {avg_out_degree/Maksymalny stopień wychodzący wśród wierzchołków w grafie},
    {avg_loop_weight/Średnia waga pętli w grafie},
    {avg_path_len/Średnia długość ścieżki w grafie},
    {avg_go_path_len/Średnia długość istniejących ścieżek do globalnego optimum},
    {max_go_path_len/Długość najdłuższej istniejącej ścieżki do globalnego optimum},
    {go_path_ratio/Stosunek liczby wierzchołków, z których istnieje ścieżka do globalnego optimum do liczby wszystkich wierzchołków},
    {funnel_num/Liczba lejów w przestrzeni},
    {max_funnel_size/Rozmiar największego leja w przestrzeni},
    {mean_funnel_size/Średni rozmiar lejów w przestrzeni},
    {num_cc/Liczba spójnych podgrafów},
    {largest_cc/Rozmiar największego spójnego podgrafu},
    {largest_cc_radius/Promień największego spójnego podgrafu}}

\foreach \metric/\cap in \metrics{
    \begin{figure}[p]
        \centering
        \includegraphics[width=\textwidth]{chapters/experiments/img/merged_plots/main_snowball/\metric.png}
        \caption{\cap \space w zależności od liczby wierzchołków - próbkowanie snowball}
        \label{fig:main_snowball_\metric}
    \end{figure}
}

TODO: wstawić główne wyniki z twophase, jak już będą, Komentarz do wyników